{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc29880",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410c59ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 128/512 target list generaiton '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 128/512 target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_512 = [i.replace('seeds_2048', 'seeds_512') for i in seed]\n",
    "# seed_128 = [i.replace('seeds_2048', 'seeds_128') for i in seed]\n",
    "\n",
    "# with open('train_seed512.txt', 'w') as f:\n",
    "#     for i in seed_512:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed128.txt', 'w') as f:\n",
    "#     for i in seed_128:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67b3dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 64/32 target list generaiton '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 64/32 target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_64 = [i.replace('seeds_2048', 'seeds_64') for i in seed]\n",
    "# seed_32 = [i.replace('seeds_2048', 'seeds_32') for i in seed]\n",
    "\n",
    "# with open('train_seed64.txt', 'w') as f:\n",
    "#     for i in seed_64:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed32.txt', 'w') as f:\n",
    "#     for i in seed_32:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c572c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 64/32 target list generaiton '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 64/32 target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_64 = [i.replace('seeds_2048', 'seeds_64') for i in seed]\n",
    "# seed_32 = [i.replace('seeds_2048', 'seeds_32') for i in seed]\n",
    "\n",
    "# with open('train_seed64.txt', 'w') as f:\n",
    "#     for i in seed_64:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed32.txt', 'w') as f:\n",
    "#     for i in seed_32:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040d6ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 256/1024 target list generaiton '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 256/1024 target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_256 = [i.replace('seeds_2048', 'seeds_256') for i in seed]\n",
    "# seed_1024 = [i.replace('seeds_2048', 'seeds_1024') for i in seed]\n",
    "\n",
    "# with open('train_seed256.txt', 'w') as f:\n",
    "#     for i in seed_256:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed1024.txt', 'w') as f:\n",
    "#     for i in seed_1024:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f405c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' seed 4096/8192 target list generaiton '''\n",
    "\n",
    "with open('train_seed2048.txt', 'r') as f:\n",
    "    seed = f.read().splitlines()\n",
    "    \n",
    "seed_4096 = [i.replace('seeds_2048', 'seeds_4096') for i in seed]\n",
    "seed_8192 = [i.replace('seeds_2048', 'seeds_8192') for i in seed]\n",
    "\n",
    "with open('train_seed4096.txt', 'w') as f:\n",
    "    for i in seed_4096:\n",
    "        f.write('{}\\n'.format(i))\n",
    "        \n",
    "with open('train_seed8192.txt', 'w') as f:\n",
    "    for i in seed_8192:\n",
    "        f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6f2700",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m seed_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m seed_spx:\n\u001b[0;32m---> 14\u001b[0m     seed_dict[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/sehyun/data/Cityscapes/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_idxes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_seed2048.dict\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     17\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(seed_dict, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/d2ada/lib/python3.8/site-packages/numpy/lib/npyio.py:438\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load file containing pickled data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen allow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to interpret file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m as a pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' seed 2048 superpixel list generation '''\n",
    "\n",
    "# with open('train_seed2048.txt','r') as f:\n",
    "#     seed = f.read().splitlines()    \n",
    "# with open('train.txt', 'r') as f:\n",
    "#     slic = f.read().splitlines()\n",
    "# with open('train.dict', 'r') as f:\n",
    "#     slic_json = json.load(f)\n",
    "\n",
    "# slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "# seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "# seed_dict = {}\n",
    "# for i in seed_spx:\n",
    "#     seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "# with open('train_seed2048.dict','w') as f:\n",
    "#     json.dump(seed_dict, f)\n",
    "\n",
    "''' seed 128/512 superpixel list generation '''\n",
    "\n",
    "# with open('train_seed512.txt','r') as f:\n",
    "#     seed = f.read().splitlines()    \n",
    "# with open('train.txt', 'r') as f:\n",
    "#     slic = f.read().splitlines()\n",
    "# with open('train.dict', 'r') as f:\n",
    "#     slic_json = json.load(f)\n",
    "\n",
    "# slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "# seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "# seed_dict = {}\n",
    "# for i in seed_spx:\n",
    "#     seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "# with open('train_seed512.dict','w') as f:\n",
    "#     json.dump(seed_dict, f)\n",
    "    \n",
    "# with open('train_seed128.txt','r') as f:\n",
    "#     seed = f.read().splitlines()    \n",
    "# with open('train.txt', 'r') as f:\n",
    "#     slic = f.read().splitlines()\n",
    "# with open('train.dict', 'r') as f:\n",
    "#     slic_json = json.load(f)\n",
    "\n",
    "# slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "# seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "# seed_dict = {}\n",
    "# for i in seed_spx:\n",
    "#     seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "# with open('train_seed128.dict','w') as f:\n",
    "#     json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "460276a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 64/32 superpixel list generation '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 64/32 superpixel list generation '''\n",
    "\n",
    "# with open('train_seed64.txt','r') as f:\n",
    "#     seed = f.read().splitlines()    \n",
    "# with open('train.txt', 'r') as f:\n",
    "#     slic = f.read().splitlines()\n",
    "# with open('train.dict', 'r') as f:\n",
    "#     slic_json = json.load(f)\n",
    "\n",
    "# slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "# seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "# seed_dict = {}\n",
    "# for i in seed_spx:\n",
    "#     seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "# with open('train_seed64.dict','w') as f:\n",
    "#     json.dump(seed_dict, f)\n",
    "    \n",
    "# with open('train_seed32.txt','r') as f:\n",
    "#     seed = f.read().splitlines()    \n",
    "# with open('train.txt', 'r') as f:\n",
    "#     slic = f.read().splitlines()\n",
    "# with open('train.dict', 'r') as f:\n",
    "#     slic_json = json.load(f)\n",
    "\n",
    "# slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "# seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "# seed_dict = {}\n",
    "# for i in seed_spx:\n",
    "#     seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "# with open('train_seed32.dict','w') as f:\n",
    "#     json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed98c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 256 superpixel list generation '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 256 superpixel list generation '''\n",
    "# with open('train_seed256.txt','r') as f:\n",
    "#     seed = f.read().splitlines()    \n",
    "# with open('train.txt', 'r') as f:\n",
    "#     slic = f.read().splitlines()\n",
    "# with open('train.dict', 'r') as f:\n",
    "#     slic_json = json.load(f)\n",
    "\n",
    "# slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "# seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "# seed_dict = {}\n",
    "# for i in tqdm(seed_spx):\n",
    "#     seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "# with open('train_seed256.dict','w') as f:\n",
    "#     json.dump(seed_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73edf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 1024 superpixel list generation '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 1024 superpixel list generation '''\n",
    "# with open('train_seed1024.txt','r') as f:\n",
    "#     seed = f.read().splitlines()    \n",
    "# with open('train.txt', 'r') as f:\n",
    "#     slic = f.read().splitlines()\n",
    "# with open('train.dict', 'r') as f:\n",
    "#     slic_json = json.load(f)\n",
    "\n",
    "# slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "# seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "# seed_dict = {}\n",
    "# for i in tqdm(seed_spx):\n",
    "#     seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "# with open('train_seed1024.dict','w') as f:\n",
    "#     json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59885899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:16<00:00, 21.79it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed 4096 superpixel list generation '''\n",
    "with open('train_seed4096.txt','r') as f:\n",
    "    seed = f.read().splitlines()    \n",
    "with open('train.txt', 'r') as f:\n",
    "    slic = f.read().splitlines()\n",
    "with open('train.dict', 'r') as f:\n",
    "    slic_json = json.load(f)\n",
    "\n",
    "slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "seed_dict = {}\n",
    "for i in tqdm(seed_spx):\n",
    "    seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "with open('train_seed4096.dict','w') as f:\n",
    "    json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f7c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' seed 8192 superpixel list generation '''\n",
    "with open('train_seed8192.txt','r') as f:\n",
    "    seed = f.read().splitlines()    \n",
    "with open('train.txt', 'r') as f:\n",
    "    slic = f.read().splitlines()\n",
    "with open('train.dict', 'r') as f:\n",
    "    slic_json = json.load(f)\n",
    "\n",
    "slic_spx = [i.split('\\t')[-1] for i in slic]\n",
    "seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "seed_dict = {}\n",
    "for i in tqdm(seed_spx):\n",
    "    seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()\n",
    "\n",
    "with open('train_seed8192.dict','w') as f:\n",
    "    json.dump(seed_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b09b2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:02<00:00, 1307.17it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed 8192 superpixel list generation '''\n",
    "with open('train_seed8192.txt','r') as f:\n",
    "    seed = f.read().splitlines()    \n",
    "\n",
    "seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "seed_dict = {}\n",
    "for i in tqdm(seed_spx):\n",
    "    seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].tolist()[-1] + 1\n",
    "    \n",
    "with open('train_seed8192_namx.dict','w') as f:\n",
    "    json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d4b5715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 128/512 dominant target list generaiton '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 2048 dominant target list generation '''\n",
    "\n",
    "# prefix = 'superpixel_seed/cityscapes/seeds_2048/train/gtFine_dominant'\n",
    "\n",
    "# with open('train_seed2048.txt','r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "\n",
    "# target_path = [i.split('\\t')[1] for i in seed]\n",
    "# target_id = [i.split('/')[-1].split('_gtFine')[0] for i in target_path]\n",
    "# replaced_path = ['{}/{}.png'.format(prefix, i.split('/')[-1]) for i in target_id]\n",
    "# seed_modified = ['{}\\t{}\\t{}'.format(i.split('\\t')[0], j, i.split('\\t')[2]) for i,j in zip(seed, replaced_path)]\n",
    "\n",
    "# with open('train_seed2048_dominant.txt', 'w') as f:\n",
    "#     for i in seed_modified:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "\n",
    "''' seed 128/512 dominant target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048_dominant.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_512 = [i.replace('seeds_2048', 'seeds_512') for i in seed]\n",
    "# seed_128 = [i.replace('seeds_2048', 'seeds_128') for i in seed]\n",
    "\n",
    "# with open('train_seed512_dominant.txt', 'w') as f:\n",
    "#     for i in seed_512:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed128_dominant.txt', 'w') as f:\n",
    "#     for i in seed_128:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f854d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' seed 64/32 dominant target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048_dominant.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_64 = [i.replace('seeds_2048', 'seeds_64') for i in seed]\n",
    "# seed_32 = [i.replace('seeds_2048', 'seeds_32') for i in seed]\n",
    "\n",
    "# with open('train_seed64_dominant.txt', 'w') as f:\n",
    "#     for i in seed_64:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed32_dominant.txt', 'w') as f:\n",
    "#     for i in seed_32:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "196dd62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 256/1024 dominant target list generaiton '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 256/1024 dominant target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048_dominant.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_256 = [i.replace('seeds_2048', 'seeds_256') for i in seed]\n",
    "# seed_1024 = [i.replace('seeds_2048', 'seeds_1024') for i in seed]\n",
    "\n",
    "# with open('train_seed256_dominant.txt', 'w') as f:\n",
    "#     for i in tqdm(seed_256):\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed1024_dominant.txt', 'w') as f:\n",
    "#     for i in tqdm(seed_1024):\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "119cb7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:00<00:00, 478068.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:00<00:00, 485451.85it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed 4096/8192 dominant target list generaiton '''\n",
    "\n",
    "with open('train_seed2048_dominant.txt', 'r') as f:\n",
    "    seed = f.read().splitlines()\n",
    "    \n",
    "seed_4096 = [i.replace('seeds_2048', 'seeds_4096') for i in seed]\n",
    "seed_8192 = [i.replace('seeds_2048', 'seeds_8192') for i in seed]\n",
    "\n",
    "with open('train_seed4096_dominant.txt', 'w') as f:\n",
    "    for i in tqdm(seed_4096):\n",
    "        f.write('{}\\n'.format(i))\n",
    "        \n",
    "with open('train_seed8192_dominant.txt', 'w') as f:\n",
    "    for i in tqdm(seed_8192):\n",
    "        f.write('{}\\n'.format(i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec163d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 2048 multi-label target list generation '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 2048 multi-label target list generation '''\n",
    "\n",
    "# prefix = 'superpixel_seed/cityscapes/seeds_2048/train/gtFine_or'\n",
    "\n",
    "# with open('train_seed2048.txt','r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "\n",
    "# target_path = [i.split('\\t')[1] for i in seed]\n",
    "# target_id = [i.split('/')[-1].split('_gtFine')[0] for i in target_path]\n",
    "# replaced_path = ['{}/{}.npy'.format(prefix, i.split('/')[-1]) for i in target_id]\n",
    "# seed_modified = ['{}\\t{}\\t{}'.format(i.split('\\t')[0], j, i.split('\\t')[2]) for i,j in zip(seed, replaced_path)]\n",
    "\n",
    "# with open('train_seed2048_or.txt', 'w') as f:\n",
    "#     for i in seed_modified:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "\n",
    "# # ''' seed 128/512 or target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048_or.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_512 = [i.replace('seeds_2048', 'seeds_512') for i in seed]\n",
    "# seed_128 = [i.replace('seeds_2048', 'seeds_128') for i in seed]\n",
    "\n",
    "# with open('train_seed512_or.txt', 'w') as f:\n",
    "#     for i in seed_512:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed128_or.txt', 'w') as f:\n",
    "#     for i in seed_128:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fcb2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 64/32 or target list generaiton '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 64/32 or target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048_or.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_64 = [i.replace('seeds_2048', 'seeds_64') for i in seed]\n",
    "# seed_32 = [i.replace('seeds_2048', 'seeds_32') for i in seed]\n",
    "\n",
    "# with open('train_seed64_or.txt', 'w') as f:\n",
    "#     for i in seed_64:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed32_or.txt', 'w') as f:\n",
    "#     for i in seed_32:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0ac686a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seed 256/1024 or target list generaiton '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' seed 256/1024 or target list generaiton '''\n",
    "\n",
    "# with open('train_seed2048_or.txt', 'r') as f:\n",
    "#     seed = f.read().splitlines()\n",
    "    \n",
    "# seed_256 = [i.replace('seeds_2048', 'seeds_256') for i in seed]\n",
    "# seed_1024 = [i.replace('seeds_2048', 'seeds_1024') for i in seed]\n",
    "\n",
    "# with open('train_seed256_or.txt', 'w') as f:\n",
    "#     for i in tqdm(seed_256):\n",
    "#         f.write('{}\\n'.format(i))\n",
    "        \n",
    "# with open('train_seed1024_or.txt', 'w') as f:\n",
    "#     for i in tqdm(seed_1024):\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "328cbb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:00<00:00, 535492.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:00<00:00, 545512.56it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed 4096/8192 or target list generaiton '''\n",
    "\n",
    "with open('train_seed2048_or.txt', 'r') as f:\n",
    "    seed = f.read().splitlines()\n",
    "    \n",
    "seed_4096 = [i.replace('seeds_2048', 'seeds_4096') for i in seed]\n",
    "seed_8192 = [i.replace('seeds_2048', 'seeds_8192') for i in seed]\n",
    "\n",
    "with open('train_seed4096_or.txt', 'w') as f:\n",
    "    for i in tqdm(seed_4096):\n",
    "        f.write('{}\\n'.format(i))\n",
    "        \n",
    "with open('train_seed8192_or.txt', 'w') as f:\n",
    "    for i in tqdm(seed_8192):\n",
    "        f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee38ce49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:01<00:00, 1528.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [01:26<00:00, 34.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [01:24<00:00, 35.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:09<00:00, 23.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:10<00:00, 22.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:02<00:00, 24.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:31<00:00, 19.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:14<00:00, 22.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:27<00:00, 20.21it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed superpixel dict update '''\n",
    "nseg_list = [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 32768]\n",
    "\n",
    "for nseg in nseg_list:\n",
    "    \n",
    "    with open('train_seed{}.txt'.format(nseg),'r') as f:\n",
    "        seed = f.read().splitlines()    \n",
    "    seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "    seed_dict = {}\n",
    "    \n",
    "    for i in tqdm(seed_spx):\n",
    "        seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].size\n",
    "\n",
    "    with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f88922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:00<00:00, 712299.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:00<00:00, 793971.39it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed 32768/131072 or target list generaiton '''\n",
    "\n",
    "with open('train_seed2048_or.txt', 'r') as f:\n",
    "    seed = f.read().splitlines()\n",
    "    \n",
    "seed_32768 = [i.replace('seeds_2048', 'seeds_32768') for i in seed]\n",
    "seed_131072 = [i.replace('seeds_2048', 'seeds_131072') for i in seed]\n",
    "\n",
    "with open('train_seed32768_or.txt', 'w') as f:\n",
    "    for i in tqdm(seed_32768):\n",
    "        f.write('{}\\n'.format(i))\n",
    "        \n",
    "with open('train_seed131072_or.txt', 'w') as f:\n",
    "    for i in tqdm(seed_131072):\n",
    "        f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b37e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' seed 32768/131072 target list generaiton '''\n",
    "\n",
    "with open('train_seed2048.txt', 'r') as f:\n",
    "    seed = f.read().splitlines()\n",
    "    \n",
    "seed_32768 = [i.replace('seeds_2048', 'seeds_32768') for i in seed]\n",
    "seed_131072 = [i.replace('seeds_2048', 'seeds_131072') for i in seed]\n",
    "\n",
    "with open('train_seed32768.txt', 'w') as f:\n",
    "    for i in seed_32768:\n",
    "        f.write('{}\\n'.format(i))\n",
    "        \n",
    "with open('train_seed131072.txt', 'w') as f:\n",
    "    for i in seed_131072:\n",
    "        f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1934994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:01<00:00, 24.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [02:04<00:00, 23.87it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed superpixel dict update '''\n",
    "nseg_list = [32768, 131072]\n",
    "\n",
    "for nseg in nseg_list:\n",
    "    \n",
    "    with open('train_seed{}.txt'.format(nseg),'r') as f:\n",
    "        seed = f.read().splitlines()    \n",
    "    seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "    seed_dict = {}\n",
    "    \n",
    "    for i in tqdm(seed_spx):\n",
    "        seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].size\n",
    "\n",
    "    with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af31997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:46<00:00, 64.08it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed superpixel dict update '''\n",
    "nseg_list = [2048]\n",
    "\n",
    "for nseg in nseg_list:\n",
    "    \n",
    "    with open('train_seed{}.txt'.format(nseg),'r') as f:\n",
    "        seed = f.read().splitlines()    \n",
    "    seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "    seed_dict = {}\n",
    "    \n",
    "    for i in tqdm(seed_spx):\n",
    "        seed_dict[i] = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes'].size\n",
    "\n",
    "    with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96af3f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'superpixel_seed/cityscapes/seeds_2048/train/label/aachen_000000_000019.pkl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_spx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041dba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_dict_2048 = np.load('/home/sehyun/data/Cityscapes/superpixel_seed/cityscapes/seeds_2048/train/label/cologne_000098_000019.pkl'.format(i), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee5a3a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2047, [1716])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value = seed_dict_2048['valid_idxes'].max()\n",
    "(max_value, [i for i in range(max_value+1) if i not in seed_dict_2048['valid_idxes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5053224f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1716]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(2048) if i not in seed_dict_2048['valid_idxes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e51bdb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [00:02<00:00, 1169.51it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed superpixel dict update '''\n",
    "nseg_list = [32]\n",
    "\n",
    "for nseg in nseg_list:\n",
    "    \n",
    "    with open('train_seed{}.txt'.format(nseg),'r') as f:\n",
    "        seed = f.read().splitlines()    \n",
    "    seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "    seed_dict = {}\n",
    "    \n",
    "    for i in tqdm(seed_spx):\n",
    "        valid_idxes = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes']\n",
    "        max_value = valid_idxes.max()\n",
    "        seed_dict[i] = (max_value.item()+1, [i for i in range(max_value+1) if i not in valid_idxes])\n",
    "\n",
    "    with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(seed_dict.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12aaa640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(max_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c2a4aca",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_seed\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.dict\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(nseg),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m         \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/d2ada/lib/python3.8/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/anaconda3/envs/d2ada/lib/python3.8/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/d2ada/lib/python3.8/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/d2ada/lib/python3.8/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/d2ada/lib/python3.8/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/d2ada/lib/python3.8/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int32 is not JSON serializable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15e016cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [01:51<00:00, 26.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [01:37<00:00, 30.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [01:42<00:00, 28.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [04:53<00:00, 10.14it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed superpixel dict update '''\n",
    "nseg_list = [2048, 128, 512, 8192]\n",
    "\n",
    "for nseg in nseg_list:\n",
    "    \n",
    "    with open('train_seed{}.txt'.format(nseg),'r') as f:\n",
    "        seed = f.read().splitlines()    \n",
    "    seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "    seed_dict = {}\n",
    "    \n",
    "    for i in tqdm(seed_spx):\n",
    "        valid_idxes = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes']\n",
    "        max_value = valid_idxes.max()\n",
    "        seed_dict[i] = (max_value.item()+1, [i for i in range(max_value+1) if i not in valid_idxes])\n",
    "\n",
    "    with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "684b69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2975/2975 [13:15<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "''' seed superpixel dict update '''\n",
    "nseg_list = [32768]\n",
    "\n",
    "for nseg in nseg_list:\n",
    "    \n",
    "    with open('train_seed{}.txt'.format(nseg),'r') as f:\n",
    "        seed = f.read().splitlines()    \n",
    "    seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "    seed_dict = {}\n",
    "    \n",
    "    for i in tqdm(seed_spx):\n",
    "        valid_idxes = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes']\n",
    "        max_value = valid_idxes.max()\n",
    "        seed_dict[i] = (max_value.item()+1, [i for i in range(max_value+1) if i not in valid_idxes])\n",
    "\n",
    "    with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' seed superpixel dict update '''\n",
    "nseg_list = [32]\n",
    "\n",
    "for nseg in nseg_list:\n",
    "    \n",
    "    with open('train_seed{}.txt'.format(nseg),'r') as f:\n",
    "        seed = f.read().splitlines()    \n",
    "    seed_spx = [i.split('\\t')[-1] for i in seed]\n",
    "    seed_dict = {}\n",
    "    \n",
    "    for i in tqdm(seed_spx):\n",
    "        valid_idxes = np.load('/home/sehyun/data/Cityscapes/{}'.format(i), allow_pickle=True)['valid_idxes']\n",
    "        max_value = valid_idxes.max()\n",
    "        seed_dict[i] = (max_value.item()+1, [i for i in range(max_value+1) if i not in valid_idxes])\n",
    "\n",
    "    with open('train_seed{}.dict'.format(nseg),'w') as f:\n",
    "        json.dump(seed_dict, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "d2ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
